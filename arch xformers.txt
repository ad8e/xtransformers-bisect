

stories 2732634
chars 2191281193
longest 4433
chars used: 52428800
dataset proportion used: 0.023926094089376872
74 chars used:
 !"$',-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Transformer                              [1, 1024, 75]             --
├─Embedding: 1-1                         [1, 1024, 384]            29,184
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-1                        [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-1               [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-1             [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-3                   [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-2                        --                        (recursive)
│    │    └─Attention: 3-2               --                        (recursive)
│    │    │    └─Linear: 4-2             [1, 1024, 384]            147,456
│    │    └─MLP: 3-3                     [1, 1024, 384]            --
│    │    │    └─Linear: 4-3             [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-4             [1, 1024, 384]            589,824
│    └─Block: 2-3                        [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-4               [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-5             [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-5                   [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-4                        --                        (recursive)
│    │    └─Attention: 3-5               --                        (recursive)
│    │    │    └─Linear: 4-6             [1, 1024, 384]            147,456
│    │    └─MLP: 3-6                     [1, 1024, 384]            --
│    │    │    └─Linear: 4-7             [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-8             [1, 1024, 384]            589,824
│    └─Block: 2-5                        [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-7               [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-9             [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-7                   [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-6                        --                        (recursive)
│    │    └─Attention: 3-8               --                        (recursive)
│    │    │    └─Linear: 4-10            [1, 1024, 384]            147,456
│    │    └─MLP: 3-9                     [1, 1024, 384]            --
│    │    │    └─Linear: 4-11            [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-12            [1, 1024, 384]            589,824
│    └─Block: 2-7                        [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-10              [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-13            [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-9                   [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-8                        --                        (recursive)
│    │    └─Attention: 3-11              --                        (recursive)
│    │    │    └─Linear: 4-14            [1, 1024, 384]            147,456
│    │    └─MLP: 3-12                    [1, 1024, 384]            --
│    │    │    └─Linear: 4-15            [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-16            [1, 1024, 384]            589,824
│    └─Block: 2-9                        [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-13              [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-17            [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-11                  [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-10                       --                        (recursive)
│    │    └─Attention: 3-14              --                        (recursive)
│    │    │    └─Linear: 4-18            [1, 1024, 384]            147,456
│    │    └─MLP: 3-15                    [1, 1024, 384]            --
│    │    │    └─Linear: 4-19            [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-20            [1, 1024, 384]            589,824
│    └─Block: 2-11                       [1, 1024, 384]            1,179,648
│    │    └─Attention: 3-16              [1, 1024, 384]            147,456
│    │    │    └─Linear: 4-21            [1, 1024, 1152]           442,368
├─RotaryEmbedding: 1-13                  [1, 6, 1024, 64]          --
├─ModuleList: 1-14                       --                        (recursive)
│    └─Block: 2-12                       --                        (recursive)
│    │    └─Attention: 3-17              --                        (recursive)
│    │    │    └─Linear: 4-22            [1, 1024, 384]            147,456
│    │    └─MLP: 3-18                    [1, 1024, 384]            --
│    │    │    └─Linear: 4-23            [1, 1024, 1536]           589,824
│    │    │    └─Linear: 4-24            [1, 1024, 384]            589,824
├─Linear: 1-15                           [1, 1024, 75]             28,875
==========================================================================================
Total params: 18,637,515
Trainable params: 18,637,515
Non-trainable params: 0
Total mult-adds (M): 10.67
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 173.63
Params size (MB): 42.70
Estimated Total Size (MB): 216.34
==========================================================================================
embedding.weight [0.07222044467926025, 0.0002466899168211967]
lm_head.weight [0.029499053955078125, 0.0003385088057257235]
lm_head.bias [0.028143297880887985, -0.004681044723838568]
transformerblocks.0.attn.W_in.weight [0.029476899653673172, -2.103354017890524e-05]
transformerblocks.0.attn.W_o.weight [0.02944881096482277, -5.418198634288274e-05]
transformerblocks.0.mlp.c_fc.weight [0.029466232284903526, 3.8243073504418135e-05]
transformerblocks.0.mlp.c_proj.weight [0.014749730937182903, 1.4924058632459491e-05]
transformerblocks.1.attn.W_in.weight [0.0294551532715559, -3.7791128306707833e-06]
transformerblocks.1.attn.W_o.weight [0.029450329020619392, -5.075669105281122e-05]
transformerblocks.1.mlp.c_fc.weight [0.02947237528860569, -4.303917012293823e-05]
transformerblocks.1.mlp.c_proj.weight [0.014734992757439613, -2.917986421380192e-05]
transformerblocks.2.attn.W_in.weight [0.02944042533636093, 1.7343079434795072e-06]
transformerblocks.2.attn.W_o.weight [0.029465526342391968, 8.179756696335971e-05]
transformerblocks.2.mlp.c_fc.weight [0.029460366815328598, 7.436219220835483e-06]
transformerblocks.2.mlp.c_proj.weight [0.014739740639925003, 4.5906341256340966e-05]
transformerblocks.3.attn.W_in.weight [0.02948768436908722, -4.886882015853189e-05]
transformerblocks.3.attn.W_o.weight [0.029531454667448997, 5.4151646509126294e-06]
transformerblocks.3.mlp.c_fc.weight [0.029484063386917114, 1.4071130181037006e-06]
transformerblocks.3.mlp.c_proj.weight [0.014739594422280788, 1.2925876035296824e-05]
transformerblocks.4.attn.W_in.weight [0.029441766440868378, -5.642178803100251e-05]
transformerblocks.4.attn.W_o.weight [0.029477309435606003, -2.5920646294252947e-05]
transformerblocks.4.mlp.c_fc.weight [0.029450273141264915, -2.1479796487255953e-05]
transformerblocks.4.mlp.c_proj.weight [0.0147195840254426, 5.277984200802166e-06]
transformerblocks.5.attn.W_in.weight [0.029416805133223534, 3.478482904029079e-05]
transformerblocks.5.attn.W_o.weight [0.02946995384991169, -2.4874872906366363e-05]
transformerblocks.5.mlp.c_fc.weight [0.029472198337316513, -4.609325515048113e-06]
transformerblocks.5.mlp.c_proj.weight [0.01473312173038721, 2.74363028438529e-05]

wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.
wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.
wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
wandb: Currently logged in as: ad8e (team-ad8e). Use `wandb login --relogin` to force relogin

Tracking run with wandb version 0.16.1
Run data is saved locally in /content/drive/MyDrive/tinystories/wandb/run-20240106_020839-ky2gvk8d
Syncing run from scratch to Weights & Biases (docs)
View project at https://wandb.ai/team-ad8e/tinystories2
View run at https://wandb.ai/team-ad8e/tinystories2/runs/ky2gvk8d

/usr/local/lib/python3.10/dist-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.10/dist-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.10/dist-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.10/dist-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,

d'3S7CIjv?k:'0298QG@3bR0TI!5u.30"j!G3PQfT3ihA0w5Wi.LMv'fmY.@jTiS$S;j8YS!zAuFYIPfTLmVuV2nGG@tB7GVQ3aK"0u3L5TSNR61m9Ls.1uoI5T:n3sIVj88USrytNFH.cVx"ziBl-jof:L8HlpKL!TV9.?LPcT9hUSMoYqr5J85;QFAYaYLSiKjLJ8GmYoik0L-MtmatoXNsr9wuCjLFY.aJv
GJI73a8,H.,toP5Y;FUY9Y"u,Q09z"PV1l3q:KKAdo0,vU3ITUP?55-0iFrPGLG0
qB60RipNzNJPziT7pCSvhTyome.YNk our tR-,Ui7YB@5Lf5151Pi 98SL.m:8KIy.ueLiLvX69!fukV'7la ;Su6:sSTxktL3-f05LjewI5vLnz5o!ovNLpiz1sAVV52Kz:q;Io,Hh8uCP:rj1LFw0XCTrNLrt@1X5vvK"TPvY3sEGLr.5qUVjacTVvvjroK0dL2pB2Hu"q0LF SoPLoafm5O oC5J:v.1TCWPA;1L@zlUsUQkI1.2-:F5w!3ipJr@HT9YM@H38i953FYu1vz.TdPi@72L i9oH.K
riHN3noP @SYLiUv. q8iBTLH4Uv;?mT3ok,vt5USf;Y5TFXHvW@2kMG3h.GLXNjeVu"a Qo5JL1,nkS9hzLLYK.vfZjfBGl@di05iX3i5QYs?HToW57FaPfWk!0j!PT!13afV6TRK'$a:X3aih@-tL ',o1PiNH@1dhTC6?o@5BHdntKv;:41jP0l7KnsL@9hxvG:UR;trmzTF0.L0-mZzV:40KT
3,Tp;i,qulB30szdd3-j!PK Hs7T-@.!Th5zwR3!v.raU"liTsM5HoLUxSr9M5GYX ,WL:L850T'L2PT!v?GTKP3pf6UN?2HZ;C.HNLHNjp,H-9qUC@0pI:,Td.rz::3P M-T
v5;.VCoTko-G0r 9-rXzrzvr";d523i03sLH0rw 1ip.f6i@0R5QX"mH8Q90XvinL
o:kCKTY3Yz
Once upon a time, there was a young cat named Joe. And she was very sad. Her friend, Tom, he looked feeling from it of his friend, a way black sat and said, "No, I will be fireple for we need to see it near the shelf."
Jill shop the bird felt pad. Tom and his mom took a town on the top. But then something unow they looked in his dad. Tom and he was better with other thing and see what was inside. They saw a little bird scared and were giving so fush.
When they got to the box, and they helped to be something new that he she would taking and ran after the day fell. Tom and Tom felt dad at the toy bird. The dog was very excited.@Once upon a time, there was a girl named Mia. A boat was scared because he was so biggenet. The dog was not seed helped the gent in his room. Tom was very happy. Every day, she found something even when he had something up.
Mia felt so happy again, in the truck came back to him. Tom thought it was too before the porinally. The fairy was came and wanted to play with the wheel took the wen
Once upon a time, there was a talking cat named Tom. Tom liked to play on the ground with his mom. They liked to leave the cat and shiny on the floor. It would be ready for a favorite mean to make it leave.
One day, Tom saw a big red lady on the floor. He wanted to help the lady, so they tried to talk and talk, but it could not shine it. Tom felt bad that he should never talk to the far.
Tom played with the cat and then said, "Wow, Tom!" Tom read the cat and the lady all lived happily. Her mom took the lady and went to talk to him again. They all the day and watched the far away from the farm.@Once upon a time, there was a big hat. The big hat was a miney forgiven. The farmer was far away. It was big on the big planet broke and soft brilliant way all the dollive far.
One day, the farmer and the stage. The farmer saw a little red and said, "Please I tripped over, I feel mine." The big farmer smiled and watched the stage.
The stage tripped into the farmer, but he did not want to be a friend to have it. The end.
The big pond was three years old. The book was still scared of the beach. He wanted to help the big pond with the beach. He told the big pond while he was trying to help it get scared.
One day, the big pond was walking in the grass. The big pond was not there, but the big pond was scared. The book held the pond and saw a pretty green bug. The pond was helping all the beach and the green bug was scared.
The big pond was scared of the beach. The beach went inside the bug and left it. They saw a big tree and a lot of leaves to the ground. The big pond was not fair anymore. It flew down through the tree and the big pond he was so happy. It flew down and got the big pond that helped the bug be careful.@Once upon a time, there was a penguin. It was a funny cat. The cat wanted to reach the big tree. One day, the cat saw a big plant. The penguin was ready to set.
The penguin did not want to help her. The cat ran to help her. The cat gave the big bear a big mountain. The penguin was scared and sad. They were happy.@On
Once upon a time, there was a graceful parrot. It was in a small house with a big smile on its face. The big sun was very hot, and it flew away.
One day, the big sun seemed to read a step in the graceful sun. It wanted to lift the step too. It was a small, colorful girl, like the graceful sun. The girl was scared, but she had never seen a step.
So, the girl said to the big sun behind a tree. Her face thought it was the step. Then, the girl ran away from the step. The girl felt happy too. She knew that helping each other could not think about what she could do.@One day, a little boy named Tim found a book on the ground. He put it in a big book and the smoke to his friend, Sam. Sam was sad because he had a small problem.
Tim asked Sam, "Can I have your small problem?" Sam said, "No, I have no friends. They need your special treat to keep things from him." Tim thought for a moment and then said, "Okay, let's keep you safe."
Tim threw the book in the ground and carried it up to Sam and Sam. They were so happy an@
Once upon a time, in a small house, there was a little dog named Max. Max loved to play with his friends. One day, Max found a pretty cat stuck in a path. He wanted to see what was inside the cat's car. Max loved to take the cat with his mom.
Max's mom said, "Don't worry, Max. It will fall into a tree. It will make your toys and nice friends in the path." Max was sad, but he wanted to be in the tree. Max ran to his mom and told him they could fall on the tree.
Max's mom saw what was on the cat and decided to take it away to a big pile of tower. He looked up and saw a toy with a big smile. Max picked up the toy and put the toy in his hands. Max was so happy to have his new friend. He played with the toy and watched it stuck inside the tree. From that day on, Max loved to play with his toys in the path.@Once upon a time, in a big pond, there was a little boy named Tim. Tim loved to play with his friends. One day, he and his friends went to the park.
Tim went to the park with his friends. They saw a big, talkin@
embedding.weight [0.08864350616931915, 0.00036634382558986545]
lm_head.weight [0.07076261192560196, 0.0005445830756798387]
lm_head.bias [0.11731234937906265, -0.08183696866035461]
transformerblocks.0.attn.W_in.weight [0.028080925345420837, -1.1797006663982756e-05]
transformerblocks.0.attn.W_o.weight [0.02596786804497242, -4.490173523663543e-05]
transformerblocks.0.mlp.c_fc.weight [0.03860281780362129, -5.354863787943032e-06]
transformerblocks.0.mlp.c_proj.weight [0.028743157163262367, 3.647163248388097e-05]
transformerblocks.1.attn.W_in.weight [0.034980956465005875, 2.4376724468311295e-05]
transformerblocks.1.attn.W_o.weight [0.03840756043791771, -4.521003211266361e-05]
transformerblocks.1.mlp.c_fc.weight [0.04705917835235596, 0.00012895175314042717]
transformerblocks.1.mlp.c_proj.weight [0.03684288635849953, -2.1707386622438207e-05]
transformerblocks.2.attn.W_in.weight [0.038216304033994675, 9.053921417034871e-07]
transformerblocks.2.attn.W_o.weight [0.040661223232746124, 8.047924347920343e-05]
transformerblocks.2.mlp.c_fc.weight [0.04742879047989845, 8.410480222664773e-05]
transformerblocks.2.mlp.c_proj.weight [0.03748057782649994, 3.4527860407251865e-05]
transformerblocks.3.attn.W_in.weight [0.04005343094468117, -1.8279937648912892e-05]
transformerblocks.3.attn.W_o.weight [0.043246883898973465, -3.4324173157074256e-06]
transformerblocks.3.mlp.c_fc.weight [0.048286810517311096, 9.31357208173722e-05]
transformerblocks.3.mlp.c_proj.weight [0.040488243103027344, 1.3250654774310533e-05]
transformerblocks.4.attn.W_in.weight [0.042898207902908325, -5.149930439074524e-05]
transformerblocks.4.attn.W_o.weight [0.047720033675432205, -1.7584417946636677e-05]
transformerblocks.4.mlp.c_fc.weight [0.04871300607919693, 4.742504097521305e-05]
transformerblocks.4.mlp.c_proj.weight [0.04151042178273201, 1.554684786242433e-05]
transformerblocks.5.attn.W_in.weight [0.040698517113924026, 3.868940257234499e-05]
transformerblocks.5.attn.W_o.weight [0.04183885082602501, -5.245884312898852e-05]
transformerblocks.5.mlp.c_fc.weight [0.04774779453873634, -3.977369544827525e-07]
transformerblocks.5.mlp.c_proj.weight [0.041431695222854614, 6.331676559057087e-05]

Run history:

loss	█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
lr	▁▂▃▃▄▅▆▆▇████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
time	▁▃▄▃▄▆▆▅█▆█▆█▄▅▆▅▆▆▆▅▆▆▆█▇▆▇▆▇▅▆▆▆▆▅▆▆▆▆

Run summary:

loss	0.53639
lr	0.0
time	222090815

View run from scratch at: https://wandb.ai/team-ad8e/tinystories2/runs/ky2gvk8d
Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
Find logs at: ./wandb/run-20240106_020839-ky2gvk8d/logs
